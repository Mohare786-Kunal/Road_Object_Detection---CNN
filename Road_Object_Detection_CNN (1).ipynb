{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#***Road Object Detection Model***"
      ],
      "metadata": {
        "id": "P21MC3u8ERN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import cv2"
      ],
      "metadata": {
        "id": "_-5MVUBPDe_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names for objects on the road\n",
        "classes = {\n",
        "    0: \"Car\",\n",
        "    1: \"Pedestrian\",\n",
        "    2: \"Bicycle\",\n",
        "    3: \"Motorcycle\",\n",
        "    4: \"Bus\",\n",
        "    5: \"Truck\",\n",
        "    6: \"Traffic Light\",\n",
        "    7: \"Stop Sign\",\n",
        "    8: \"Crosswalk\",\n",
        "    9: \"Road Sign\"\n",
        "}"
      ],
      "metadata": {
        "id": "JTsIuroiDlYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images and labels for training\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = tf.keras.preprocessing.image.load_img(os.path.join(folder, filename), target_size=(150, 150))\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        images.append(img_array)\n",
        "        labels.append(int(folder[-1]))  # Extract the class number from the folder name\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "hQISfBfiDpNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "train_data = []\n",
        "train_labels = []\n",
        "for i in range(10):  # Assuming there are 10 classes\n",
        "    folder_name = f\"train_class_{i}\"\n",
        "    images, labels = load_images_from_folder(folder_name)\n",
        "    train_data.extend(images)\n",
        "    train_labels.extend(labels)\n",
        "\n",
        "train_data = np.array(train_data)\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "PMJLWWlZDsQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "val_images = val_images / 255.0"
      ],
      "metadata": {
        "id": "AbzaZJZnDueM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 output classes for 10 objects on the road\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "reeYjzUfDw2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "DGph3QtaD2T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the video capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Loop to capture video frames\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Preprocess the frame\n",
        "    resized_frame = cv2.resize(frame, (150, 150))\n",
        "    normalized_frame = resized_frame / 255.0\n",
        "    input_frame = np.expand_dims(normalized_frame, axis=0)\n",
        "\n",
        "    # Predict objects in the frame\n",
        "    prediction = model.predict(input_frame)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Draw bounding box and label on the frame\n",
        "    label = classes[predicted_class]\n",
        "    cv2.rectangle(frame, (0, 0), (200, 50), (255, 255, 255), -1)\n",
        "    cv2.putText(frame, f\"Object: {label}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Road Object Detection', frame)\n",
        "\n",
        "    # Check for 'q' key press to exit the loop\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "wGMbbdBBKUlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Above code snippet is using RealTime capturing and identification\n",
        "#Below code provides offline prediction of the objects from the captures or clicked photo or image."
      ],
      "metadata": {
        "id": "0RWMdJbuD6g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AICUv8HTDcys"
      },
      "outputs": [],
      "source": [
        "# Single prediction,  without OpenCV code\n",
        "# Load test data\n",
        "\n",
        "test_data = []\n",
        "test_labels = []\n",
        "for i in range(10):  # 10 classes\n",
        "    folder_name = f\"test_class_{i}\"\n",
        "    images, labels = load_images_from_folder(folder_name)\n",
        "    test_data.extend(images)\n",
        "    test_labels.extend(labels)\n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize test data\n",
        "test_data = test_data / 255.0\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "def predict_single_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = img_array / 255.0\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    return f\"Predicted object: {classes[predicted_class]}\"\n",
        "\n",
        "# Single prediction\n",
        "image_path = \"car_image.jpg\"  # Replace with your image path\n",
        "prediction_result = predict_single_image(image_path)\n",
        "print(prediction_result)\n"
      ]
    }
  ]
}